{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4596175f",
   "metadata": {
    "id": "13cd4f0f",
    "outputId": "df1ef0fe-eacf-333e-f39a-7f4de8bafeb6",
    "runTime": {
     "end": 1690487712673,
     "hasRun": true,
     "output_error": false,
     "start": 1690487581878,
     "time": 130.8
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_82/1778218597.py:69: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  tk0 = tqdm(train_loader, total=len(train_loader))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9d68dadc3cc4177a2dcb94468bc5304",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  1%|█                   | 3/938 [00:00<00:34, 27.31it/s, loss=0.456]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_82/1778218597.py:43: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "249c79690af2456a8d0136a5a71b5d2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  100%|████████████████████| 938/938 [00:42<00:00, 18.40it/s, loss=0.000113]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "313466908bc24a9abe5326e825ddfdce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  100%|████████████████████| 938/938 [00:43<00:00, 17.94it/s, loss=0.000111]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.1878, Accuracy: 9452/10000 (95%)\n",
      "\n",
      "Predicted class: 5\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from flask import jsonify\n",
    "\n",
    "# Here the constants\n",
    "model_path = \"./mnist_torch.pt\"\n",
    "device = \"cpu\"\n",
    "batch_size_train = 64\n",
    "batch_size_test = 1024\n",
    "image_transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize((28, 28)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# All functions below are for loading and train models, no any code outside functions so we can safely transform this notebook to python file >>>>>>>>>>>\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5, stride=1)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5, stride=1)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv2_drop(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(x)\n",
    "        x = x.view(-1, 320)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x)\n",
    "\n",
    "\n",
    "def load_model(model_path):\n",
    "    #model = CNN()\n",
    "    #model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))\n",
    "    model = torch.load(model_path, map_location=torch.device(device))\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    return model\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    image = Image.open(image_path)\n",
    "    image = image_transform(image).unsqueeze(0)\n",
    "    return image\n",
    "\n",
    "def data_loader():\n",
    "    train_dataset = torchvision.datasets.MNIST('dataset/', train=True, download=True, transform=image_transform)\n",
    "    test_dataset = torchvision.datasets.MNIST('dataset/', train=False, download=True, transform=image_transform)\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size_train, shuffle=True)\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size_test, shuffle=True)\n",
    "    return train_dataset,train_loader,test_dataset,test_loader\n",
    "\n",
    "\n",
    "def train(model, device, train_loader, optimizer, num_epochs, log_interval=10000):\n",
    "    model.train()\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        tk0 = tqdm(train_loader, total=len(train_loader))\n",
    "        counter = 0\n",
    "        for batch_idx, (data, target) in enumerate(tk0):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = F.nll_loss(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            counter += 1\n",
    "            tk0.set_postfix(loss=(loss.item() * data.size(0) / (counter * train_loader.batch_size)))\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "# <<<<<<<<<<<<<<<< All functions above are for loading and train models, no any code outside functions so we can safely transform this notebook to python file\n",
    "\n",
    "# >>>>>>>>> All functions below to run training or prediction. Uncomment function in the bottom to train model or test prediction before deployment\n",
    "#run this function to train model\n",
    "def train_model():\n",
    "    model = CNN()\n",
    "    num_epochs = 3\n",
    "    learning_rate = 0.01\n",
    "    momentum = 0.5\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)\n",
    "    _,train_loader,_,test_loader = data_loader()\n",
    "    train(model, device, train_loader, optimizer, num_epochs)\n",
    "    test(model, device, test_loader)\n",
    "    torch.save(model, model_path)\n",
    "    \n",
    "\n",
    "# THIS IS THE MAIN FUNCTION FOR API: to predict image class, we will use it in API setup\n",
    "def predict_image(image_path):\n",
    "    image = preprocess_image(image_path)\n",
    "    with torch.no_grad():\n",
    "        model = load_model(model_path)\n",
    "        output = model(image)\n",
    "        predicted_class = torch.argmax(output, dim=1).item()\n",
    "    #we use Flask to deploy so we should return Flask Response, we use jsonify\n",
    "    return jsonify(predicted_class)\n",
    "\n",
    "#train\n",
    "#comment for api deploy, uncomment for training\n",
    "#train_model()\n",
    "\n",
    "# Predict the class of a new image\n",
    "#comment for api deploy, uncomment for prediction when you test notebook before deployment\n",
    "#predicted_class = predict_image(\"mnist-5.png\")\n",
    "#print(\"Predicted class:\", predicted_class)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
